{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 231 Machine Learning: Homework 2** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Classification**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Divya** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 23/4** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Oskar Hulthén, 950801-1195, huoskar@student.chalmers** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                  ** And: Alexander Branzell, 931003-1977, alebra@student.chalmers.se** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical problems, can be submitted as a single file named *report.pdf*. They can also be submitted in this ipynb notebook, but equations wherever required, should be formatted using LaTeX math-mode.\n",
    "* All discussion regarding practical problems, along with solutions and plots should be specified here itself. We will not generate the solutions/plots again by running your code.\n",
    "* Your name, personal number and email address should be specified above and also in your file *report.pdf*.\n",
    "* All datasets can be downloaded from the course website.\n",
    "* All tables and other additional information should be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical problems\n",
    "\n",
    "## [Naive Bayes Classifier, 6 points]\n",
    "\n",
    "A psychologist does a small survey on ''happiness''. Each respondent provides a vector with entries 1 or 0 corresponding to if they answered “yes” or “no” to a question respectively. The question vector has attributes \n",
    "$$\n",
    "x = (\\mbox{rich, married, healthy}) \\tag{1}\n",
    "$$\n",
    "\n",
    "Thus a response $(1, 0, 1)$ would indicate that the respondent was\n",
    "''rich'', ''unmarried'' and ''healthy''. In addition, each respondent\n",
    "gives a value $c = 1$ if they are content wih their life and $c = 0$\n",
    "if they’re not. The following responses were obtained.\n",
    "\n",
    "$$\n",
    "c = 1: (1, 1, 1),(0, 0, 1),(1, 1, 0),(1, 0, 1) \\\\\n",
    "c = 0: (0, 0, 0),(1, 0, 0),(0, 0, 1),(0, 1, 0)\n",
    "$$\n",
    "\n",
    "1. Using naive Bayes, what is the probability that a person is ''not rich'', ''married'' and ''healthy'' is ''content''?\n",
    "\n",
    "2. What is the probability that a person who is ''not rich'' and ''married'' is content ? (i.e. we do not know if they are ''healthy'')\n",
    "\n",
    "## [Extending Naive Bayes, 4 points]\n",
    "\n",
    "Consider now, the following vector of attributes:\n",
    "\n",
    "* $x_1 = 1$ if customer is younger than 20 and 0 otherwise.\n",
    "* $x_2 = 1$ if customer is between 20 and 30 in age, and 0 otherwise.\n",
    "* $x_3 = 1$ if customer is older than 30 and 0 otherwise\n",
    "* $x_4 = 1$ if customer walks to work and 0 otherwise.\n",
    "\n",
    "Each vector of attributes has a label ''rich'' or ''poor''. Point out potential difficulties with your approach above to training using naive Bayes. Suggest and describe how to extend your naive Bayes method to this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "For answers to the theoretical questions see the pdf report attached together with this notebook file on hand-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical problems\n",
    "\n",
    "## [Bayes classifier, 5 points]\n",
    "\n",
    "Dowload the dataset **\"dataset2.txt\"**. You can use the following code for example:\n",
    "```python\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt('dataset2.txt', delimiter=',')\n",
    "labels = data[:,-1]\n",
    "```\n",
    "The dataset contains $3$-dimensional data, $X$, generated from $2$ classes with labels, $y$ either $+1$ or $-1$.  Each row of $X$ and $y$ contain one observation and one label respectively.  There are $1000$ instances of each class. \n",
    "\n",
    "a. Assume that the class conditional density is spherical Gaussian, and both classes have equal prior. Write the expression for the Bayes (<span style=\"color:red\"> not **naive Bayes**</span>) classifier i.e. derive\n",
    "$$\n",
    "P(y_{new} = -1 | x_{new} , X, y ) \\\\\n",
    "P(y_{new} = +1 | x_{new} , X, y ) ~.\n",
    "$$\n",
    "\n",
    "It is useful to note that the dependence on training data $X, y$ for class $1$ can be expressed as: \n",
    "\n",
    "$$ \n",
    "P( x_{new} | y_{new} = 1, X, y) = P(x_{new} |\n",
    "\\hat{\\mu}_{1}, \\hat{\\sigma}^{2}_{1})\n",
    "$$\n",
    "\n",
    "where $\\hat{\\mu}_{1} \\in \\mathbb{R}^3$ and $\\hat{\\sigma}^{2}_{1}\\in \\mathbb{R}$ are MLE estimates for mean (3-dimensional) and variance based on training data with label $+1$ (and similarly for class 2 with label $-1$). \n",
    "\n",
    "b. Implement a function **sph_bayes()** which computes the probability of a new test point *Xtest* coming from class $1$ ($P1$) and class $2$ ($P2$). Finally, assign a label *Ytest* to the test point based on the probabilities $P1$ and $P2$.\n",
    "\n",
    "```python\n",
    "def sph_bayes(Xtest, ...): # other parameters needed.\n",
    "\n",
    "    return [P1, P2, Ytest]\n",
    "```\n",
    "c. Write a function **new_classifier()**\n",
    "\n",
    "```python\n",
    "def new_classifier(Xtest, mu1, mu2)\n",
    "    \n",
    "    return [Ytest]\n",
    "```\n",
    "which implements the following classifier,\n",
    "$$\n",
    "f(x) = \\mbox{sign}\\left(\\frac{(\\mu_1 - \\mu_2)^\\top (x - b) }{\\|\\mu_1 -  \\mu_2\\|_2} \\right)\n",
    "$$\n",
    "with $b = \\frac{1}{2}(\\mu_1 + \\mu_2)$.\n",
    "\n",
    "d. Report 5-fold cross validation error for both classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers:\n",
    "## a)\n",
    "Following the Bayes formula for prediction:\n",
    "$$P(t_{new}=k\\ |\\ x_{new},\\mathbf{X},\\mathbf{t}) = \\frac{p(x_{new}\\ |\\ t_{new}=k,\\mathbf{X},\\mathbf{t})P(t_{new}=k)}{\\sum _{j}p(x_{new}\\ |\\ t_{new}=j,\\mathbf{X},\\mathbf{t})P(t_{new}=j)}$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Where we have two classes $y_{new}=-1$ and $y_{new}=+1$. To predict the +1 class we get the following:\n",
    "\n",
    "$$P(y_{new}=+1\\ |\\ x_{new},\\mathbf{X},\\mathbf{t}) = \\frac{p(x_{new}\\ |\\ y_{new}=+1,\\mathbf{X},\\mathbf{t})P(y_{new}=+1)}{p(x_{new}\\ |\\ y_{new}=+1,\\mathbf{X},\\mathbf{t})P(y_{new}=+1) + p(x_{new}\\ |\\ y_{new}=-1,\\mathbf{X},\\mathbf{t})P(y_{new}=-1)}$$\n",
    "<br>\n",
    "<br>\n",
    "Given in the task is that both classes have equal prior distribution ($P(y_{new}=-1) = P(y_{new}=+1)$), meaning that the prior distribution can be removed:\n",
    "<br>\n",
    "\n",
    "$$P(y_{new}=+1\\ |\\ x_{new},\\mathbf{X},\\mathbf{t}) = \\frac{p(x_{new}\\ |\\ y_{new}=+1,\\mathbf{X},\\mathbf{t})}{p(x_{new}\\ |\\ y_{new}=+1,\\mathbf{X},\\mathbf{t}) + p(x_{new}\\ |\\ y_{new}=-1,\\mathbf{X},\\mathbf{t})}$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "Furthermore we're given the way to express dependence upon the training data as $P( x_{new}\\ |\\ y_{new} = 1, X, y) = P(x_{new} | \\hat{\\mu}_{1}, \\hat{\\sigma}^{2}_{1})$ yielding the following final expressions for Bayes classifier:\n",
    "<br>\n",
    "\n",
    "$$P(y_{new}=+1\\ |\\ x_{new},\\mathbf{X},\\mathbf{t}) = \\frac{P(x_{new}\\ |\\ \\hat{\\mu}_{+1}, \\hat{\\sigma}^{2}_{+1})}{P(x_{new}\\ |\\ \\hat{\\mu}_{+1}, \\hat{\\sigma}^{2}_{+1}) + P(x_{new}\\ |\\ \\hat{\\mu}_{-1}, \\hat{\\sigma}^{2}_{-1})}$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$P(y_{new}=-1\\ |\\ x_{new},\\mathbf{X},\\mathbf{t}) = \\frac{P(x_{new}\\ |\\ \\hat{\\mu}_{-1}, \\hat{\\sigma}^{2}_{-1})}{P(x_{new}\\ |\\ \\hat{\\mu}_{+1}, \\hat{\\sigma}^{2}_{+1}) + P(x_{new}\\ |\\ \\hat{\\mu}_{-1}, \\hat{\\sigma}^{2}_{-1})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 5-fold cross validation ======\n",
      "==== Iteration 1 ====\n",
      "Accuracy of spherical bayes: 0.998\n",
      "Accuracy of new classifier: 0.760\n",
      "==== Iteration 2 ====\n",
      "Accuracy of spherical bayes: 1.000\n",
      "Accuracy of new classifier: 0.745\n",
      "==== Iteration 3 ====\n",
      "Accuracy of spherical bayes: 0.995\n",
      "Accuracy of new classifier: 0.743\n",
      "==== Iteration 4 ====\n",
      "Accuracy of spherical bayes: 0.995\n",
      "Accuracy of new classifier: 0.777\n",
      "==== Iteration 5 ====\n",
      "Accuracy of spherical bayes: 0.998\n",
      "Accuracy of new classifier: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Task b),c) and d)\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Load the data\n",
    "data = genfromtxt('dataset2.txt', delimiter=',')\n",
    "labels = data[:,-1]\n",
    "\n",
    "# Returns the Most likely estimator for mu and sigma based on the given data and class\n",
    "# dimensions is the number of dimensions upon the data \n",
    "def mle_values(data, classifier, dimensions=3):\n",
    "    n=0\n",
    "    sum_mu  = np.zeros(dimensions) # The same amount of mu values as dimensions\n",
    "    for row in data:\n",
    "        if(row[dimensions] == classifier):  # The class of the data is located in the column after the data\n",
    "            for i in range (0,dimensions):  \n",
    "                sum_mu[i] += row[i]         # add the data to the sum\n",
    "            n += 1\n",
    "    mu = sum_mu / float(n)            # Divide the sum by the amount of points to get the mu values\n",
    "    \n",
    "    sum_sig = 0\n",
    "    for row in data:\n",
    "        if(row[dimensions] == classifier):\n",
    "            sum_sig += np.dot(np.transpose(row[0:3] - mu), row[0:3]-mu)\n",
    "            \n",
    "    sig = np.sqrt(sum2) / float(n)\n",
    "        \n",
    "    return mu, sig\n",
    "\n",
    "def sph_gauss(Xtest, mu, sig):\n",
    "    term1 = (1/ np.sqrt( (2* np.pi)**3 * np.sqrt(3)*sig**2))\n",
    "    term2 = np.exp(-1 / (2*sig**2) * np.sum(np.dot(np.transpose(Xtest-mu),Xtest-mu)**2) )\n",
    "    return term1*term2\n",
    "\n",
    "def sph_bayes(Xtest, mu_1, sig_1 , mu_m1 , sig_m1):\n",
    "    term1 = sph_gauss(Xtest,mu_1, sig_1)\n",
    "    term2 = sph_gauss(Xtest,mu_m1, sig_m1)\n",
    "    # Tie breaker: (One point seem to be precisely on the decision boundary)\n",
    "    if (term1 == 0 and term2 == 0):\n",
    "            term1 = random.random()\n",
    "            term2 = 1-term1\n",
    "    P1 = term1 / (term1+term2)\n",
    "    P2 = term2 / (term1+ term2)\n",
    "    \n",
    "    r = random.random()\n",
    "    \n",
    "    \n",
    "    if (r < P1):\n",
    "        Ytest = 1\n",
    "    else:\n",
    "        Ytest = -1\n",
    "    return [P1, P2, Ytest]\n",
    "\n",
    "def new_classifier(Xtest, mu1, mu2):\n",
    "    \n",
    "    mu = np.zeros(3)\n",
    "    mu[0] = mu1[0]-mu2[0]\n",
    "    mu[1] = mu1[1]-mu2[1]\n",
    "    mu[2] = mu1[2]-mu2[2]\n",
    "    \n",
    "    b = np.zeros(3)\n",
    "    b[0] = 1/2 * mu1[0]+mu2[0]\n",
    "    b[1] = 1/2 * mu1[1]+mu2[1]\n",
    "    b[2] = 1/2 * mu1[2]+mu2[2]\n",
    "    \n",
    "    point = Xtest-b\n",
    "    dist = np.sqrt(np.sum((mu)**2))\n",
    "\n",
    "    Ytest =np.sign( np.dot(np.transpose(mu),point) / dist)  \n",
    "    return Ytest\n",
    "\n",
    "# Main\n",
    "def taskd():\n",
    "    print(\"====== 5-fold cross validation ======\")\n",
    "    KF = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "    x = 1\n",
    "    for train_index, test_index in KF.split(data):\n",
    "        print(\"==== Iteration %i ====\" % x)\n",
    "        x += 1\n",
    "        mu_1, sig_1 = mle_values(data[train_index], 1)\n",
    "        mu_m1, sig_m1 = mle_values(data[train_index], -1)\n",
    "        bayes = 0\n",
    "        new = 0\n",
    "        n = 0\n",
    "        for i in test_index:\n",
    "            n += 1\n",
    "            [_,_,res1] = sph_bayes(data[i][0:3],mu_1, sig_1, mu_m1, sig_m1)\n",
    "            if res1 == data[i][3]:\n",
    "                bayes += 1\n",
    "            res2 = new_classifier(data[i][0:3],mu_1 , mu_m1)\n",
    "            if res2 == data[i][3]:\n",
    "                new += 1\n",
    "    \n",
    "        print(\"Accuracy of spherical bayes: %.3f\" %(bayes/float(n)) )\n",
    "        print(\"Accuracy of new classifier: %.3f\" %(new/float(n)) )\n",
    "            \n",
    "                      \n",
    "taskd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [DIGITS dataset classifer, 5 points]\n",
    "\n",
    "Load the DIGITS dataset:\n",
    "```python\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "```\n",
    "This dataset contains $1797$ samples of ten handwritten digit classes. You can further query and visualize the dataset using the various attributes of the returned dictionary:\n",
    "```python\n",
    "data = digits.data\n",
    "print(data.shape)\n",
    "target_names = digits.target_names\n",
    "print (target_names)\n",
    "import matplotlib.pyplot as plt\n",
    "y = digits.target\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "a. Use **new_classifier()** designed previously to do binary classification between classes representing digits \"*5*\" and \"*8*\".\n",
    "\n",
    "b. Investigate an alternative feature function as described below:\n",
    "\n",
    "1. Scale each pixel value to range $[0, 1] $ from original gray-scale ($0-255$). \n",
    "2. Compute variance of each row and column of the image. This will give you a new feature vector of size $16$ i.e. \n",
    "\n",
    "$$ \n",
    "x' = \\left[ \\; Var(row_1)  , Var(row_2), \\ldots , Var(row_{8}), Var(col_1), \\ldots, Var(col_{8}) \\;\\right]^T\n",
    "$$\n",
    "\n",
    "c. Report $5$-fold cross validation results for parts $(a)$ and\n",
    "$(b)$ in a single table. What can you say about the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
